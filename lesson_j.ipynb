{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_j.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tocRQFwg8XUb"
      },
      "source": [
        "#Face detection with `skimage`\n",
        "\n",
        "In this lesson, we will see how to use `skimage` tools to locate human faces in an image. The techniques below might be used as the first step in facial *recognition*; before we can try to determine who appears in an image, based on their faces, we need to *detect* the areas in the image that are faces. \n",
        "\n",
        "In the code that follows, we will use a pre-trained <a href=\"https://en.wikipedia.org/wiki/Cascading_classifiers\">cascade classifier</a>, a specific type of machine learning algorithm designed to quickly detect a given class of objects (faces, in our case) in an image. *Pre-trained* means that researchers have already developed the algorithm and have \"taught\" it how to detect objects by giving it many images that are positive and negative instances -- images that are faces and images that are not faces. All we have to do is load up the trained classifier and learn to use it.\n",
        "\n",
        "We begin, as ususal, with some standard imports and configuration to allow us to view images in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5kMRJoxVYW"
      },
      "source": [
        "# one-time imports and configuration\n",
        "import skimage.io\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 150\n",
        "\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmYR4llx-Zah"
      },
      "source": [
        "Next, we have some imports specifically related to using our cascade classifier, as shown in the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_aIJOI6I7lw"
      },
      "source": [
        "# the data module has several sample images to practice with\n",
        "from skimage import data\n",
        "# the feature.Cascade class encapsulates a cascade classifier\n",
        "from skimage.feature import Cascade\n",
        "# the patches matplotlib module will allow us to easily highlight faces\n",
        "from matplotlib import patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybYCdaYV-9uZ"
      },
      "source": [
        "Now, we can create our cascade classifier. The trained face detection classifier is provided as part of the `skimage` distribution. In order to use it, we need to determine the location and filename of the classifier configuration and parameters, which is stored in an `.xml` file somewhere on our computer. Since that location may vary considerably from installation to installation, `skimage` provides a function to return the full path to the `.xml` file, \n",
        "\n",
        "```\n",
        "data.lbp_frontal_face_cascade_filename()\n",
        "```\n",
        "\n",
        "On the author's Colab setup, a call to that function returns this path, as a Python string:\n",
        "\n",
        "```\n",
        "/usr/local/lib/python3.7/dist-packages/skimage/data/lbpcascade_frontalface_opencv.xml\n",
        "```\n",
        "\n",
        "The next cell calls the function and saves the classifier's file name in a variable named `classifierFileName`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj3xJs1b-7p4"
      },
      "source": [
        "# Get the file name of the trained classifier description\n",
        "classifierFileName = data.lbp_frontal_face_cascade_filename()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGnURKM_Ajup"
      },
      "source": [
        "Next, we create an instance of the `Cascasde` class, using the classifier parameters contained in the initiation file we found in the previous step. This is accomplised by passing the file name of the classifier description to the `Cascade` constructor, as shown in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3cO5mwV_-GC"
      },
      "source": [
        "# Initialize the detector cascade.\n",
        "detector = Cascade(classifierFileName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kll8NvvXA9za"
      },
      "source": [
        "Everything to this point we only need to do once. In other words, now that we have created our instace of the `Cascade` class, `detector`, we can use the instance to detect faces in any number of different images. \n",
        "\n",
        "So, let's start detecting faces! We will begin by trying to detect the face in one of the sample images in the `skimage.data` module. In particular, we will use an image of <a href=\"https://en.wikipedia.org/wiki/Eileen_Collins\">Eileen Collins</a>, a former NASA astronaut. We do this via the `data.astronaut()` function call. The function returns the image in a `numpy` array, just like the images we have been using all along. The array is a 3D array with RGB values in the range [0, 255].\n",
        "\n",
        "The next cell loads the image and displays it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzKlu4vzJV5H"
      },
      "source": [
        "img = data.astronaut()\n",
        "skimage.io.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRrUFeD1C4pK"
      },
      "source": [
        "Now that we have an image, we can use our trained classifier to detect the face(s) in the image. Assuming that our classifier object is named `detector`, we do this with a call to the `detector.detect_multi_scale()` method. The `multi_scale` portion of the method name means that the classifier will try to find faces of a variety of sizes in the image. \n",
        "\n",
        "This function examines all of the areas of a certain minimum size in the image, passes them through the classifier, and decides if each represents a face or not. Then, to detect faces that might be larger, the process is repeated for areas of a larger size. This whole process continues until some specified maximum size is reached. \n",
        "\n",
        "There are five parameters we have to provide, as follows. The parameters are positional, but we will provide names for the last four to make the code easier to read. \n",
        "\n",
        "First, we provide the `numpy` array representing our image. Here, we have named the array `img`. \n",
        "\n",
        "Next, we provide the `scale_factor`. This is a floating point number that dictates how quickly the search areas grow. For example, a value of 2 here would make each successive search area twice as big as the previous one. Values closer to 1 will make the classifier more accurate, but slower, while larger values will make the classifier faster but less accurate. \n",
        "\n",
        "Third is the `step_ratio` parameter. This is a floating point number that represents the step size between each search area. Using a value of 1 here will look at *all* of the possible positions for each search area in the image, resulting in a slow but more accurate search. Increasing this value puts more pixels between each successive search area, resulting in a faster but less accurate search. According to the <a href=\"https://scikit-image.org/docs/dev/api/skimage.feature.html?highlight=template#skimage.feature.Cascade\">`Cascasde` documentation</a>, values in the range [1, 1.5] provide good results. \n",
        "\n",
        "The next two parameters, `min_size` and `max_size`, are both tuples, each containing two integers. These are the minimum size and maximum size of the search areas. If we have a rough guess of how large the faces in our image are likely to be, we should bracket that assumed size between `min_size` and `max_size`, so the classifier does not spend too much time looking at areas that are either to small or too large to be actual faces in the image. \n",
        "\n",
        "The next cell shows usage of the `detect_multi_scale()` method call for the sample image. Examination of the image tells us that Col. Collins' face is approximately 100x100 pixels, so we use `min_size = (60, 60)` and `max_size = (120, 120)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd4OFlnHyvYX"
      },
      "source": [
        "# use our classifier to detect faces in the image\n",
        "detected = detector.detect_multi_scale(img, \n",
        "                                       scale_factor = 1.1, \n",
        "                                       step_ratio = 1, \n",
        "                                       min_size = (60, 60), \n",
        "                                       max_size = (120, 120))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxE-w-TaIcxs"
      },
      "source": [
        "The `detect_multi_scale()` method returns a list of dictionaries, where each dictionary has information about one of the faces detected in the image. Each dictionary has four keys:\n",
        "\n",
        "- `'r'` : row of the top-left corner of the face\n",
        "- `'c'` : column of the top-left corner of the face\n",
        "- `'width'` : width of the face\n",
        "- `'height'` : height of the face\n",
        "\n",
        "In other words, the list of dictionaries describes rectangles that surround each of the faces detected by the classifier. \n",
        "\n",
        "We can use that information in a variety of ways. For instance, we could now use slicing to extract sub-images that represente just the faces, in preparation for using other machine learning tools to recognize the faces.\n",
        "\n",
        "Here, we will simply use the list of dictionaries to draw a colored rectangle for each face on top of the original image. The next cell shows one way to accomplish this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZK1iRyCHf_s"
      },
      "source": [
        "# put the original image in the plot area\n",
        "plt.imshow(img)\n",
        "\n",
        "# get the plot area's drawing surface\n",
        "img_desc = plt.gca()\n",
        "\n",
        "# for each of the detected faces...\n",
        "for face in detected:\n",
        "    # draw a rectangle showing the face's location\n",
        "    img_desc.add_patch(\n",
        "        patches.Rectangle(\n",
        "            (face['c'], face['r']),\n",
        "            face['width'],\n",
        "            face['height'],\n",
        "            fill=False,\n",
        "            color='r',\n",
        "            linewidth=2\n",
        "        )\n",
        "    )\n",
        "\n",
        "# display the annoated image\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOu7lmTfLIWF"
      },
      "source": [
        "> ---\n",
        "> **Dectect faces in your own image.**\n",
        "> \n",
        "> Now it is time for you to try your hand at face \n",
        "> detection! Find an image of your own choosing that \n",
        "> contains multiple faces, like a group photo, for \n",
        "> instance. Load that image, then apply the \n",
        "> `detector.detect_multi_scale()` method to try to \n",
        "> find the faces in the image. \n",
        "> \n",
        "> This detector seems to be sensitive to the \n",
        "> `scale_factor`, `min_size`, and `max_size` \n",
        "> parameters, so you will probably have to experiment\n",
        "> with these values in order to detect as many faces \n",
        "> as possible.\n",
        "> \n",
        "> ---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uItTeKsAIa5M"
      },
      "source": [
        "# TODO: load your own image into the img variable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKJtIV3kMSgs"
      },
      "source": [
        "# TODO: use detector.detect_multi_scale() to find the faces\n",
        "# use our classifier to detect faces in the image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2QBifBCMeGd"
      },
      "source": [
        "# TODO: execute this cell to show highlight the faces\n",
        "# put the original image in the plot area\n",
        "plt.imshow(img)\n",
        "\n",
        "# get the plot area's drawing surface\n",
        "img_desc = plt.gca()\n",
        "\n",
        "# for each of the detected faces...\n",
        "for face in detected:\n",
        "    # draw a rectangle showing the face's location\n",
        "    img_desc.add_patch(\n",
        "        patches.Rectangle(\n",
        "            (face['c'], face['r']),\n",
        "            face['width'],\n",
        "            face['height'],\n",
        "            fill=False,\n",
        "            color='r',\n",
        "            linewidth=2\n",
        "        )\n",
        "    )\n",
        "\n",
        "# display the annoated image\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZzdIlnmMnF3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}