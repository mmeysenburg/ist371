{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_b.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voFcM9bTsda5"
      },
      "source": [
        "#Image representation in skimage\r\n",
        "\r\n",
        "##Images are represented as NumPy arrays\r\n",
        "\r\n",
        "Computerized images are represented as rectangular arrays of individually-colored square pixels, and that the color of each pixel is represented as an RGB triplet of numbers. In skimage, images are stored in a manner very consistent with this concept. In particular, images are stored as three-dimensional NumPy arrays.\r\n",
        "\r\n",
        "The rectangular shape of the array corresponds to the shape of the image, although the order of the coordinates are reversed. The \"depth\" of the array for an skimage image is three, with one layer for each of the three channels. The differences in the order of coordinates and the order of the channel layers can cause some confusion, so we should spend a bit more time looking at that.\r\n",
        "\r\n",
        "When we think of a pixel in an image, we think of its (x, y) coordinates (in a left-hand coordinate system) like (113, 45) and its color, specified as a RGB triple like (245, 134, 29). In an skimage image, the same pixel would be specified with (y, x) coordinates (45, 113) and RGB color (245, 134, 29).\r\n",
        "\r\n",
        "Let us take a look at this idea visually. Consider this image of a chair:\r\n",
        "\r\n",
        "<img src=\"https://datacarpentry.org/image-processing/fig/02-chair-orig.jpg\" alt=\"color chair\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "\r\n",
        "A visual representation of how this image is stored as a NumPy array is:\r\n",
        "\r\n",
        "<img src=\"https://datacarpentry.org/image-processing/fig/02-chair-layers-rgb.png\" alt=\"color chair layers\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "\r\n",
        "So, when we are working with skimage images, we specify the y coordinate first, then the x coordinate. And, the colors are stored as RGB values – red in layer 0, green in layer 1, blue in layer 2.\r\n",
        "\r\n",
        "---\r\n",
        "> **Coordinate and color channel order**\r\n",
        "> \r\n",
        "> CAUTION: it is vital to remember the order of the coordinates and color\r\n",
        "> channels when dealing with images as NumPy arrays. If we are manipulating or \r\n",
        "> accessing an image array directly, we specifiy the y coordinate first, then \r\n",
        "> the x. Further, the first channel stored is the red channel, followed by the \r\n",
        "> green, and then the blue.\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWUGFYZFunTZ"
      },
      "source": [
        "##Reading, displaying, and saving images\r\n",
        "\r\n",
        "Skimage provides easy-to-use functions for reading, displaying, and saving images. All of the popular image formats, such as BMP, PNG, JPEG, and TIFF are supported, along with several more esoteric formats. See the skimage documentation for more information.\r\n",
        "\r\n",
        "Let us examine a simple Python program to load, display, and save an image to a different format. The first few lines are in the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp7RJgYGsap-"
      },
      "source": [
        "import skimage.io\r\n",
        "\r\n",
        "# read image; use path / filename to open local images\r\n",
        "image = skimage.io.imread('https://i.imgur.com/44YFZww.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6LZNIpov1Dp"
      },
      "source": [
        "First, we import the `io` module of skimage (`skimage.io`) so we can read and write images. Then, we use the `skimage.io.imread()` function to read a JPEG image of the chair shown above from cloud storage. Skimage reads the image, converts it from JPEG into a NumPy array, and returns the array; we save the array in a variable named `image`.\r\n",
        "\r\n",
        "Next, we will display the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwI9VGGivyu3"
      },
      "source": [
        "# pyplot is used to display images in Jupyter\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "# set DPI so that the image appears larger\r\n",
        "import matplotlib as mpl\r\n",
        "mpl.rcParams['figure.dpi'] = 150\r\n",
        "\r\n",
        "# display the image\r\n",
        "skimage.io.imshow(image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pHM5qphw54S"
      },
      "source": [
        "If we wish to run a Python program from our operating system, rather than code in a Jupyter notebook, this code will dispaly the image:\r\n",
        "\r\n",
        "```\r\n",
        "import skimage.viewer\r\n",
        "\r\n",
        "# display image\r\n",
        "viewer = skimage.viewer.ImageViewer(image)\r\n",
        "viewer.show()\r\n",
        "```\r\n",
        "\r\n",
        "We can also save the image in another format, as shown in the next cell. Note that this saves the new image in the Jupyter Colab file system; if we want, we can download the image to our local machine. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxEaVnLOwoho"
      },
      "source": [
        "# save a new version in .tif format\r\n",
        "skimage.io.imsave(\"chair.tif\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy1QePkhyCct"
      },
      "source": [
        "The `imsave()` function automatically determines the type of the file, based on the file extension we provide. In this case, the `.tif` extension causes the image to be saved as a TIFF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgHAVscoyNeL"
      },
      "source": [
        "---\r\n",
        "> **Resizing an image**\r\n",
        "> \r\n",
        "> Using your mobile phone, tablet, web cam, or digital camera, take an\r\n",
        "> image, or use an existing image. Either upload it to a cloud storage site \r\n",
        "> that allows direct access of the image via a URL, or uploade it into the \r\n",
        "> Jupyter Colab file system. \r\n",
        "> \r\n",
        "> Then, in the code cell below, write Python code to read your image into a \r\n",
        "> variable named `image`. \r\n",
        "> \r\n",
        "> Then, resize the image by a factor of 50 percent, using the code \r\n",
        "> included in the cell\r\n",
        "> \r\n",
        "> Finally, display the image and then write the resized image out to a file\r\n",
        "> named `resized.jpg`. Download the resized image, and examine its \r\n",
        "> properties to verify it has been resized properly.\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8DxUDz3xu42"
      },
      "source": [
        "import skimage.transform\r\n",
        "\r\n",
        "# TODO: code to load your image into a variable named image\r\n",
        "\r\n",
        "# code to resize image; do not modify\r\n",
        "new_shape = (image.shape[0] // 2, image.shape[1] // 2, image.shape[2])\r\n",
        "small = skimage.transform.resize(image=image, output_shape=new_shape)\r\n",
        "\r\n",
        "# TODO: code to display the resized image\r\n",
        "\r\n",
        "# TODO: code to write resized image to a file named resized.jpg\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qvcuUTs0q3b"
      },
      "source": [
        "##Manipulating pixels\r\n",
        "\r\n",
        "If we desire or need to, we can individually manipulate the colors of pixels by changing the numbers stored in the image's NumPy array.\r\n",
        "\r\n",
        "For example, suppose we are interested in this maize root cluster image. We want to be able to focus our program’s attention on the roots themselves, while ignoring the black background.\r\n",
        "\r\n",
        "<img src=\"https://datacarpentry.org/image-processing/fig/02-roots.jpg\" alt=\"root image\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "\r\n",
        "Since the image is stored as an array of numbers, we can simply look through the array for pixel color values that are less than some threshold value. This process is called *thresholding*, and we will see more powerful methods to perform the thresholding task in the Thresholding lesson. Here, though, we will look at a simple and elegant NumPy method for thresholding. Let us develop a program that keeps only the pixel color values in an image that have value greater than or equal to 128. This will keep the pixels that are brighter than half of \"full brightness;\" i.e., pixels that do not belong to the black background. We will start by reading the image and displaying it.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rca_Ig0bDc"
      },
      "source": [
        "# load and display the image\r\n",
        "image = skimage.io.imread('https://i.imgur.com/y2Mxtzy.jpg')\r\n",
        "skimage.io.imshow(image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3YnRkk17z3"
      },
      "source": [
        "Now we can threshold the image and display the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3rFYUIi1roN"
      },
      "source": [
        "# keep only high-intensity pixels\r\n",
        "image[image < 128] = 0\r\n",
        "\r\n",
        "# display modified image\r\n",
        "skimage.io.imshow(image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60dVTdN_2OxG"
      },
      "source": [
        "The NumPy command to ignore all low-intensity pixels is `img[img < 128] = 0`. Every pixel color value in the whole 3-dimensional array with a value less that 128 is set to zero. In this case, the result is an image in which the extraneous background detail has been removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9n1qDyn3KFU"
      },
      "source": [
        "---\r\n",
        "> **Keeping only low intensity pixels**\r\n",
        "> \r\n",
        "> In the previous example, we showed how we could use Python and skimage to \r\n",
        "> turn on only the high intensity pixels from an image, while turning all \r\n",
        "> the low intensity pixels off. Now, you can practice doing the opposite – \r\n",
        "> keeping all the low intensity pixels while changing the high intensity \r\n",
        "> ones. Consider this image of a Su-Do-Ku puzzle.\r\n",
        "> \r\n",
        "> <img src=\"https://datacarpentry.org/image-processing/fig/02-sudoku.png\" alt=\"SuDoKu puzzle\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "> \r\n",
        "> In the cell below, write code that loads this image\r\n",
        "> ('https://i.imgur.com/NfjbVgc.png`), and then replaces all of the white\r\n",
        "> pixels with a light gray color, say with all three color channel values\r\n",
        "> for each formerly white pixels set to 128. Then display the new image.\r\n",
        "> Your result should look like this:\r\n",
        "> <img src=\"https://datacarpentry.org/image-processing/fig/02-sudoku-gray.png\" alt=\"Gray SuDoKu puzzle\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V34uQo3h2KOr"
      },
      "source": [
        "# TODO: write your code here\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr_3MgmKIYVJ"
      },
      "source": [
        "##Converting images to grayscale\r\n",
        "\r\n",
        "It is often easier to work with grayscale images, which have a single channel, instead of color images, which have three channels. Skimage offers the function `skimage.color.rgb2gray()` to achieve this. This function adds up the three color channels in a way that matches human color perception, see the skimage documentation for details. It returns a grayscale image with floating point values in the range from 0 to 1. We can use the `function skimage.util.img_as_ubyte()` in order to convert it back to the original data type and the data range back 0 to 255. Note that it is often better to use image values represented by floating point values, because using floating point numbers is numerically more stable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3dXYbWn4spM"
      },
      "source": [
        "# read input image\r\n",
        "image = skimage.io.imread('https://i.imgur.com/44YFZww.jpg')\r\n",
        "\r\n",
        "# convert to grayscale and display\r\n",
        "gray_image = skimage.color.rgb2gray(image)\r\n",
        "skimage.io.imshow(gray_image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y6H4RPuJK6p"
      },
      "source": [
        "We can also load color images as grayscale directly by passing the argument `as_gray=True` to `skimage.io.imread()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysI-ZnlFJFlT"
      },
      "source": [
        "# read input image\r\n",
        "gray_image = skimage.io.imread('https://i.imgur.com/44YFZww.jpg', as_gray=True)\r\n",
        "\r\n",
        "# display\r\n",
        "skimage.io.imshow(gray_image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk_6l98IJ-kI"
      },
      "source": [
        "##Access via slicing\r\n",
        "\r\n",
        "Since skimage images are stored as NumPy arrays, we can use array slicing to select rectangular areas of an image. Then, we could save the selection as a new image, change the pixels in the image, and so on. It is important to remember that coordinates are specified in `(y, x)` order and that color values are specified in `(r, g, b)` order when doing these manipulations.\r\n",
        "\r\n",
        "Consider this image of a whiteboard, and suppose that we want to create a sub-image with just the portion that says \"odd + even = odd,\" along with the red box that is drawn around the words.\r\n",
        "\r\n",
        "<img src=\"https://datacarpentry.org/image-processing/fig/02-board.jpg\" alt=\"Whiteboard1\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "\r\n",
        "We can use a tool such as ImageJ to determine the coordinates of the corners of the area we wish to extract. If we do that, we might settle on a rectangular area with an upper-left coordinate of (135, 60) and a lower-right coordinate of (480, 150), as shown in this version of the whiteboard picture:\r\n",
        "\r\n",
        "<img src=\"https://datacarpentry.org/image-processing/fig/02-board-coordinates.jpg\" alt=\"Whiteboard2\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "\r\n",
        "Note that the coordinates in the preceding image are specified in `(x, y)` order. Now if our entire whiteboard image is stored as an skimage image named `image`, we can create a new image of the selected region with a statement like this:\r\n",
        "\r\n",
        "`clip = image[60:151, 135:481, :]`\r\n",
        "\r\n",
        "Our array slicing specifies the range of y-coordinates first, `60:151`, and then the range of x-coordinates, `135:481`. Note we go one beyond the maximum value in each dimension, so that the entire desired area is selected. The third part of the slice, `:`, indicates that we want all three color channels in our new image.\r\n",
        "\r\n",
        "Code to create the subimage would start by loading the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK0u_DuaJ1sv"
      },
      "source": [
        "# load and display the image\r\n",
        "image = skimage.io.imread('https://i.imgur.com/PTd2st4.jpg')\r\n",
        "skimage.io.imshow(image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmf2wBmYZXc4"
      },
      "source": [
        "Then we use array slicing to create a new image with our selected area, and display that image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkcC7mXMZTl_"
      },
      "source": [
        "# extract, display, and save sub-image\r\n",
        "clip = image[60:151, 135:481, :]\r\n",
        "skimage.io.imshow(clip)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFAMiOn8Zh8_"
      },
      "source": [
        "We can also change the values in an image by manipulating the numbers in the NumPy array, as shown in the following code cell.\r\n",
        "\r\n",
        "First, we sample the color at a particular location of the image, saving it in a NumPy array named `color`, a $1 \\times 1 \\times 3$ array with the blue, green, and red color values for the pixel located at $\\left(x = 90, y = 330\\right)$. Then, with the `img[60:151, 135:481] = color` command, we modify the image in the specified area. In this case, the command \"erases\" that area of the whiteboard, replacing the words with a white color, as shown in the final image produced by the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n10SYZoLZfL6"
      },
      "source": [
        "# replace clipped area with sampled color\r\n",
        "color = image[330, 90]\r\n",
        "image[60:151, 135:481] = color\r\n",
        "\r\n",
        "skimage.io.imshow(image)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxP8UiehaMlB"
      },
      "source": [
        "---\r\n",
        "> **Practicing with slices**\r\n",
        "> \r\n",
        "> Load and display the maize root image from above. Then, create, display, \r\n",
        "> and save a sub-image containing only the plant and its roots. You may \r\n",
        "> want to download the original image and use an image viewer or analysis \r\n",
        "> tool, such as ImageJ, to determine the bounds of the area you will extract\r\n",
        "> using slicing.\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNu9JIv2aKH8"
      },
      "source": [
        "# TODO: Write code to extract only the plant and roots from the maize image\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm0OjEDlbNJy"
      },
      "source": [
        "##Metadata\r\n",
        "\r\n",
        "JPEG and TIFF images support the inclusion of *metadata* in images. Metadata is textual information that is contained within an image file. Metadata holds information about the image itself, such as when the image was captured, where it was captured, what type of camera was used and with what settings, etc. We normally don’t see this metadata when we view an image, but we can access it if we wish. For example, consider this image of a tree flowering in spring:\r\n",
        "\r\n",
        "<img src=\"https://datacarpentry.org/image-processing/fig/01-metadata-before.jpg\" alt=\"Flowers\" style=\"float: left; margin-right:10px;\"/>\r\n",
        "\r\n",
        "What metadata do you suppose this image contains? One way to find out is to use the Details tab of the file properties dialog in Windows, or a utility like ImageMagick, via the `identify -verbose` command. Metadata for this image, collected via ImageMagick, looks like this (plus another 100 lines or so):\r\n",
        "\r\n",
        "```\r\n",
        "[Jpeg] Compression Type:\tBaseline\r\n",
        "[Jpeg] Data Precision:\t8 bits\r\n",
        "[Jpeg] Image Height:\t463 pixels\r\n",
        "[Jpeg] Image Width:\t624 pixels\r\n",
        "[Jpeg] Number of Components:\t3\r\n",
        "[Jpeg] Component 1:\tY component: Quantization table 0, Sampling factors 2 horiz/2 vert\r\n",
        "[Jpeg] Component 2:\tCb component: Quantization table 1, Sampling factors 1 horiz/1 vert\r\n",
        "[Jpeg] Component 3:\tCr component: Quantization table 1, Sampling factors 1 horiz/1 vert\r\n",
        "[Jfif] Version:\t1.1\r\n",
        "[Jfif] Resolution Units:\tinch\r\n",
        "[Jfif] X Resolution:\t72 dots\r\n",
        "[Jfif] Y Resolution:\t72 dots\r\n",
        "[Exif SubIFD] Exposure Time:\t657/1000000 sec\r\n",
        "[Exif SubIFD] F-Number:\tF2\r\n",
        "[Exif SubIFD] Exposure Program:\tProgram normal\r\n",
        "[Exif SubIFD] ISO Speed Ratings:\t40\r\n",
        "[Exif SubIFD] Exif Version:\t2.20\r\n",
        "[Exif SubIFD] Date/Time Original:\t2017:04:10 12:04:06\r\n",
        "[Exif SubIFD] Date/Time Digitized:\t2017:04:10 12:04:06\r\n",
        "[Exif SubIFD] Components Configuration:\tYCbCr\r\n",
        "[Exif SubIFD] Shutter Speed Value:\t1/1520 sec\r\n",
        "[Exif SubIFD] Aperture Value:\tF2\r\n",
        "[Exif SubIFD] Brightness Value:\t8.89\r\n",
        "[Exif SubIFD] Exposure Bias Value:\t0 EV\r\n",
        "[Exif SubIFD] Max Aperture Value:\tF2\r\n",
        "[Exif SubIFD] Subject Distance:\t0.0 metres\r\n",
        "[Exif SubIFD] Metering Mode:\tCenter weighted average\r\n",
        "[Exif SubIFD] Flash:\tFlash did not fire, auto\r\n",
        "[Exif SubIFD] Focal Length:\t3.82 mm\r\n",
        "[Exif SubIFD] Sub-Sec Time:\t025669\r\n",
        "[Exif SubIFD] Sub-Sec Time Original:\t025669\r\n",
        "[Exif SubIFD] Sub-Sec Time Digitized:\t025669\r\n",
        "[Exif SubIFD] FlashPix Version:\t1.00\r\n",
        "[Exif SubIFD] Color Space:\tsRGB\r\n",
        "[Exif SubIFD] Exif Image Width:\t4160 pixels\r\n",
        "[Exif SubIFD] Exif Image Height:\t3088 pixels\r\n",
        "[Exif SubIFD] Sensing Method:\tOne-chip color area sensor\r\n",
        "[Exif SubIFD] Scene Type:\tDirectly photographed image\r\n",
        "[Exif SubIFD] Custom Rendered:\tCustom process\r\n",
        "[Exif SubIFD] Exposure Mode:\tAuto exposure\r\n",
        "[Exif SubIFD] White Balance Mode:\tAuto white balance\r\n",
        "[Exif SubIFD] Scene Capture Type:\tStandard\r\n",
        "[Exif SubIFD] Contrast:\tNone\r\n",
        "[Exif SubIFD] Saturation:\tNone\r\n",
        "[Exif SubIFD] Sharpness:\tNone\r\n",
        "[Exif SubIFD] Subject Distance Range:\tUnknown\r\n",
        "[Exif SubIFD] Unknown tag (0xea1c):\t[2060 bytes]\r\n",
        "[Exif SubIFD] Unknown tag (0xea1d):\t4264\r\n",
        "[Exif IFD0] Unknown tag (0x0100):\t4160\r\n",
        "[Exif IFD0] Unknown tag (0x0101):\t3088\r\n",
        "[Exif IFD0] Image Description:\tFlowering tree\r\n",
        "[Exif IFD0] Make:\tmotorola\r\n",
        "[Exif IFD0] Model:\tNexus 6\r\n",
        "[Exif IFD0] Orientation:\tTop, left side (Horizontal / normal)\r\n",
        "[Exif IFD0] X Resolution:\t72 dots per inch\r\n",
        "[Exif IFD0] Y Resolution:\t72 dots per inch\r\n",
        "[Exif IFD0] Resolution Unit:\tInch\r\n",
        "[Exif IFD0] Software:\tHDR+ 1.0.126161355r\r\n",
        "[Exif IFD0] Date/Time:\t2017:04:10 12:04:06\r\n",
        "[Exif IFD0] Artist:\tMark M. Meysenburg\r\n",
        "[Exif IFD0] YCbCr Positioning:\tCenter of pixel array\r\n",
        "[Exif IFD0] Unknown tag (0x4746):\t5\r\n",
        "[Exif IFD0] Unknown tag (0x4749):\t99\r\n",
        "[Exif IFD0] Windows XP Title:\tFlowering tree\r\n",
        "[Exif IFD0] Windows XP Author:\tMark M. Meysenburg\r\n",
        "[Exif IFD0] Windows XP Subject:\tNature\r\n",
        "[Exif IFD0] Unknown tag (0xea1c):\t[2060 bytes]\r\n",
        "[Interoperability] Interoperability Version:\t1.00\r\n",
        "[GPS] GPS Version ID:\t2.200\r\n",
        "[GPS] GPS Latitude Ref:\tN\r\n",
        "[GPS] GPS Latitude:\t40.0° 37.0' 19.33999999999571\"\r\n",
        "[GPS] GPS Longitude Ref:\tW\r\n",
        "[GPS] GPS Longitude:\t-96.0° 56.0' 46.74000000003048\"\r\n",
        "[GPS] GPS Altitude Ref:\tSea level\r\n",
        "[GPS] GPS Altitude:\t405 metres\r\n",
        "[GPS] GPS Time-Stamp:\t17:4:3 UTC\r\n",
        "```\r\n",
        "\r\n",
        "Reviewing the metadata, you can see things like the location where the image was taken, the make and model of the Android smartphone used to capture the image, the date and time when it was captured, and more. Two tags, containing the image description and the “artist,” were added manually. Depending on how you intend to use images, the metadata contained within the images may be important or useful to you. However, care must be taken when using our computer vision library, skimage, to write images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25EciX72c6yy"
      },
      "source": [
        "---\r\n",
        "> **Metadata and skimage**\r\n",
        "> \r\n",
        "> What happens to the metadata of an image when it is read into, and \r\n",
        "> written from, a Python program using skimage?\r\n",
        ">\r\n",
        "> To answer this question, write Python code to read in the \r\n",
        "> flowering tree image (https://i.imgur.com/YBPWsJR.jpg) and save it to\r\n",
        "> a file named `flowers.jpg`. Then, examine the metadata in the file you \r\n",
        "> saved. Is the metadata the same? If not, what are some key differences?\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvxMGltDa2ho"
      },
      "source": [
        "# TODO: write code to load / save the flowering tree image\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZXzXMkceVr6"
      },
      "source": [
        "---\r\n",
        "> **Slicing and the colorimetric challenge**\r\n",
        "> \r\n",
        "> Earlier, we were introduced to a colorimetric challenge, namely, graphing \r\n",
        "> the color values of a solution in a titration, to see when the color \r\n",
        "> change takes place. Let's start thinking about how to solve that problem.\r\n",
        ">\r\n",
        "> One part of our ultimate solution will be sampling the color channel \r\n",
        "> values from an image of the solution. To make our graph more reliable, we \r\n",
        "> will want to calculate a mean channel value over several pixels, rather \r\n",
        "> than simply focusing on one pixel from the image.\r\n",
        ">\r\n",
        "> Download this image of a frame from the titration video by clicking on \r\n",
        "> the image:\r\n",
        ">\r\n",
        "> <a href=\"https://i.imgur.com/Llw7EdF.png\"><img src=\"https://i.imgur.com/Llw7EdF.png\" alt=\"Titration frame\" style=\"float: left; margin-right:10px;\"></a>\r\n",
        "> \r\n",
        "> Find the $\\left(x, y\\right)$ coordinates of an area of the image you \r\n",
        "> think would be good to sample in order to find the average channel \r\n",
        "> values. Then, write a small Python program that computes the mean channel \r\n",
        "> values for a 10 × 10 pixel kernel centered around the coordinates you \r\n",
        "> chose. Print the results to the screen, in a format like this:\r\n",
        ">\r\n",
        "> ```\r\n",
        "> Avg. red value: 193.7778\r\n",
        "> Avg. green value: 189.1481\r\n",
        "> Avg. blue value: 178.6049\r\n",
        "> ```\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "874tQo9Jd7jZ"
      },
      "source": [
        "# TODO: find the mean channel values for a 10x10 channel\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCpLb9TphBEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}